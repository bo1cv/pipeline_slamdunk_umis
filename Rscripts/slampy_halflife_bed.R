library(stringr)
library(tidyverse)
library("optparse")
library("matrixStats")

### Parse input options
option_list = list(
            make_option(c("-d", "--count-directory"),
                        type="character",
                        dest = "count_dir",
                        help="full path directory of tsv count files generated by slamdunk"),
            make_option(c("-t", "--cpm--threshold"),
                        type="double",
                        dest = "cpm_cutoff",
                        help="expression threshold, CPM cutoff"),
            make_option(c("-b", "--background"),
                        type="integer",
                        dest = "bg",
                        help="user specify if ctrl samples without 4SU are present for analysis (0: no, 1:yes)"),
            make_option(c("-o", "--output-directory"),
                        type="character",
                        dest = "out_dir",
                        help="full path of output directory")

                        )

arguments <- parse_args(OptionParser(option_list = option_list))

setwd(arguments$count_dir)

# setwd("/mnt/sharc/shared/sudlab1/General/projects/SLAMseq_CHO_Mikayla/cho_slam/slam/count/")
# #setwd("/mnt/sharc/shared/sudlab1/General/projects/Mikayla/slam_herzog/slamdunk/count/")
# arguments <- data.frame(cpm_cutoff = 1,
#                         bg = 1)


# Create Filter ConversionRate table by CPM cut off -----------------------------------------------------------------
###CPM cut off
data_CPM_R1 = list.files(pattern="*h-R1.*_tcount.tsv")
names_CPM_R1 = str_remove_all(data_CPM_R1, pattern = "trimmed-")
names_CPM_R1 = str_remove(names_CPM_R1, pattern = "_processed_slamdunk_mapped_filtered_dedup_tcount.tsv")
CPM_R1 <- lapply(data_CPM_R1, read.table, header = T, colClasses=c(rep("character", 6), rep("numeric",10)), skip = 2)
names(data_CPM_R1) <- names_CPM_R1
head(CPM_R1)
filter_CPM_R1 <- lapply(CPM_R1, subset, ReadsCPM >= arguments$cpm_cutoff)
filter_CPM_R1 <- lapply(filter_CPM_R1, subset, select = c("Chromosome","Start","End","Name","Length","Strand"))
filter_CPM_R1 <- lapply(filter_CPM_R1, unite, "Coordinate",sep = "_") %>% lapply("[[", 1)
overlap_filter_CPM_R1 <- Reduce(intersect, filter_CPM_R1)
rm(CPM_R1, filter_CPM_R1, data_CPM_R1, names_CPM_R1)
head(overlap_filter_CPM_R1)

data_CPM_R2 = list.files(pattern="*R2.*_tcount.tsv")
names_CPM_R2 = str_remove_all(data_CPM_R2, pattern = "trimmed-")
names_CPM_R2 = str_remove(names_CPM_R2, pattern = "_processed_slamdunk_mapped_filtered_dedup_tcount.tsv")
CPM_R2 <- lapply(data_CPM_R2, read.table, header = T, colClasses=c(rep("character", 6), rep("numeric",10)), skip = 2)
filter_CPM_R2 <- lapply(CPM_R2, subset, ReadsCPM >= arguments$cpm_cutoff)
filter_CPM_R2 <- lapply(filter_CPM_R2, subset, select = c("Chromosome","Start","End","Name","Length","Strand"))
filter_CPM_R2 <- lapply(filter_CPM_R2, unite, "Coordinate",sep = "_") %>% lapply("[[", 1)
overlap_filter_CPM_R2 <- Reduce(intersect, filter_CPM_R2)
rm(CPM_R2, filter_CPM_R2, data_CPM_R2, names_CPM_R2)

data_CPM_R3 = list.files(pattern="*R3.*_tcount.tsv")
names_CPM_R3 = str_remove_all(data_CPM_R3, pattern = "trimmed-")
names_CPM_R3 = str_remove(names_CPM_R3, pattern = "_processed_slamdunk_mapped_filtered_dedup_tcount.tsv")
CPM_R3 <- lapply(data_CPM_R3, read.table, header = T, colClasses=c(rep("character", 6), rep("numeric",10)), skip = 2)
filter_CPM_R3 <- lapply(CPM_R3, subset, ReadsCPM >= arguments$cpm_cutoff)
filter_CPM_R3 <- lapply(filter_CPM_R3, subset, select = c("Chromosome","Start","End","Name","Length","Strand"))
filter_CPM_R3 <- lapply(filter_CPM_R3, unite, "Coordinate",sep = "_") %>% lapply("[[", 1)
overlap_filter_CPM_R3 <- Reduce(intersect, filter_CPM_R3)
rm(CPM_R3, filter_CPM_R3, data_CPM_R3, names_CPM_R3)

total <- Reduce(intersect, list(overlap_filter_CPM_R1, overlap_filter_CPM_R2, overlap_filter_CPM_R3)) %>% as.data.frame() %>% unite("Coordinate",sep = "_", remove = T)

rm( overlap_filter_CPM_R1, overlap_filter_CPM_R2, overlap_filter_CPM_R3)

# Load ConvRate tables ----------------------------------------------------

###Load sample table (no bg)
data_ConvRate = list.files(pattern= regex("*h-R..*_tcount.tsv"))
names_ConvRate = str_remove_all(data_ConvRate, pattern = "trimmed-")
names_ConvRate = str_remove(names_ConvRate, pattern = "_processed_slamdunk_mapped_filtered_dedup_tcount.tsv")
ConvRate <- lapply(data_ConvRate, read.table, header = T, colClasses=c(rep("character", 6), rep("numeric",10)), skip = 2)
names(ConvRate) <- names_ConvRate
coor <- subset(ConvRate[[1]] ,select = c("Chromosome","Start","End","Name","Length","Strand")) %>% unite("Coordinate",sep = "_", remove = T)
ConvRate <- lapply(ConvRate, subset, select = "ConversionRate")
ConvRate <- bind_cols(list(coor, ConvRate), .id = NULL)
names(ConvRate) <- c("Coordinate", names_ConvRate)
row.names(ConvRate) <- ConvRate$Coordinate
ConvRate <- ConvRate[-1]
head(ConvRate)

###Remove bg from data if any
if (arguments$bg == 1) {
  data_bg = list.files(pattern= regex("*no4su-R..*_tcount.tsv"))
  bg_convrate <- lapply(data_bg,read.table, header = T, colClasses=c(rep("character", 6), rep("numeric",10)), skip = 2)
  coor <- subset(bg_convrate[[1]] ,select = c("Chromosome","Start","End","Name","Length","Strand")) %>% unite("Coordinate",sep = "_", remove = T)
  bg_convrate <- lapply(bg_convrate, subset, select = "ConversionRate")
  bg_convrate <- bind_cols(list(coor, bg_convrate), .id = NULL)
  if (ncol(bg_convrate) > 2) {avg_bg <- apply(bg_convrate[,2:ncol(bg_convrate)], 1, mean)
  ConvRate <- sweep(ConvRate, 1, avg_bg, '-')
  } else {ConvRate <- sweep(ConvRate, 1, bg_convrate[, "ConversionRate"], '-') }
}

###Filter CPM >= cpm_cutoff
filtre_ConvRate <- subset(ConvRate, rownames(ConvRate) %in% total$Coordinate)
head(filtre_ConvRate)

#/!\#######select for our timepoints
#filtre_ConvRate <- select(filtre_ConvRate, matches( c("-0h-", "3h", "12h")))

#Normalize on T0
avg_0h <- dplyr::select(filtre_ConvRate, matches("-0h-")) %>% apply(1, mean)
ConvRate_rmbg_norm <- apply(filtre_ConvRate, 2,function(x) x/avg_0h)
ConvRate_rmbg_norm <- na.omit(ConvRate_rmbg_norm)
head(ConvRate_rmbg_norm)

setwd(arguments$out_dir)
write.table(ConvRate_rmbg_norm, file = "ConvRate_processed.tsv", quote = F, row.names = T, sep = "\t")
#Timepoints
ts = str_extract(colnames(ConvRate_rmbg_norm), regex("(?<=-).+(?=h)")) %>% as.numeric()



# Model fitting -----------------------------------------------------------

fit_model1 <- function (expressions, times) {
  moptim1 <- function(a, expression){
    mRNA_guess = exp(-a * times)
    err = expression - mRNA_guess
    sq_err = err^2
    sumsq = sum(sq_err)
    return (sumsq)
  }

  outm <- optim(1, moptim1, expression=expressions)
  minm <- outm$value
  a_m <- outm$par[1]
  half1_m <- log(2)/a_m
  mod1half = half1_m

  mod1AIC = AIC1 = 2 + length(times)*log(minm)

  #n <- length(times)
  #RMSE <- sqrt(minm/n)
  return (c(thalf_m1=half1_m, AIC_m1=mod1AIC, a_m1 = a_m))
}

model1_fits <- apply(ConvRate_rmbg_norm, 1, fit_model1, times=ts)
model1_fits <- t(model1_fits)


fit_model2 <- function(expressions2, times2){
  moptim2 <- function(x,expression) {
    a = x[1]
    c = x[2]

    mRNA_guess = (1-c)*exp(-a*times2) + c
    diff = mRNA_guess - expression
    sumsqdiff= sum(diff^2)
    return(sumsqdiff)
  }
  outm2 <- optim(c(1,0), fn=moptim2, expression = expressions2, times2)
  a_m2 <- outm2$par[1]
  c_m2 <- outm2$par[2]

  model2_halfm <- function(x, a, c) {
    mRNA_half <- (1-c) * exp(-a*x) + c
    diff = mRNA_half - 0.5
    return (sum(diff^2))
  }
  out2_2m <- optim(1, fn = model2_halfm, a = a_m2, c = c_m2)
  mod2half <- out2_2m$par[1]

  mod2AIC = AIC2 = 4 + length(times2)*log(outm2$value)

  #n <- length(times)
  #RMSE <- sqrt(out2_2m$value/n)

  return (c(thalf_m2=mod2half, AIC_m2=mod2AIC, a_m2=a_m2, c_m2=c_m2))
}

model2_fits <- apply(ConvRate_rmbg_norm, 1, fit_model2, times2=ts)
model2_fits <- t(model2_fits)
#head(model2_fits)

fit_model3 <- function (times3, expressions3){
  moptim3 <- function(x, expression){
    a = x[1]
    b = x[2]
    c = x[3]

    mRNA_guess = (1-c)*exp(-b*times3) + c*exp(-a*times3)
    diff = mRNA_guess - expression
    sumqdiff2 = sum(diff^2)
    return(sumqdiff2)
  }
  out3m <- optim(c(1,1,0.1), fn=moptim3, expression = expressions3, times3)
  a_m3 <- out3m$par[1]
  b_m3 <- out3m$par[2]
  c_m3 <- out3m$par[3]

  model3_halfm <- function(x, a,b,c){
    mRNA_halfm <- c * exp(-a*x)+(1-c)*exp(-b*x)
    diff = mRNA_halfm - 0.5
    return(sum(diff^2))
  }
  out3_3m <- optim(1, fn = model3_halfm, a = a_m3, b = b_m3, c = c_m3)
  mod3half3 <- out3_3m$par[1]

  mod3AIC = AIC3 = 6 + length(times3)*log(out3m$value)


  return(c(thalf_m3=mod3half3, AIC_m3 = mod3AIC, a_m3 = a_m3, b_m3 = b_m3, c_m3 = c_m3))
}

model3_fits <- apply(ConvRate_rmbg_norm, 1, fit_model3, times3=ts)
model3_fits <- t(model3_fits)


#Models merge
models_aic <- merge(model1_fits, model2_fits, by = "row.names")
rownames(models_aic) <- models_aic[,1]
models_aic[,1] <- NULL
models_aic <- merge(models_aic, model3_fits, by = "row.names")
head(models_aic)
names(models_aic)[1] <- "id"

# Model selection ----------------------------------------------------------

best_half <- matrix(nrow = nrow(models_aic), ncol = 3)
for (i in 1:nrow(models_aic)) {
  best_half[i,] <- c(models_aic[i,"id"], models_aic[i,paste0("thalf_m",which.min(models_aic[i, c("AIC_m1","AIC_m2","AIC_m3")]) )], paste0("model",which.min(models_aic[i, c("AIC_m1","AIC_m2","AIC_m3")]) ))
}
best_half <- data.frame(best_half, stringsAsFactors = F)
head(best_half)
best_half <- separate(best_half, X1, sep = "_", into = c("Chromosome","Start", "End", "Name", "Length", "Strand"),remove = FALSE)
best_half$X1 <- NULL
names(best_half) <- c("Chromosome","Start", "End", "Name", "Length", "Strand", "halflife","model")
best_half$halflife <- as.numeric(best_half$halflife)
head(best_half)

write.table(best_half, file = "halflife_unfiltered.tsv", quote = F, row.names = F, sep = "\t")

###Create stats of half-lifes
per_model1 = ((sum(best_half[,"model"] == "model1" ) / nrow(best_half)))*100
per_model2 = ((sum(best_half[,"model"] == "model2" ) / nrow(best_half)))*100
per_model3 = ((sum(best_half[,"model"] == "model3" ) / nrow(best_half)))*100
per0_model1 = sum(best_half[,"model"] == "model1" & best_half[,"halflife"] < 0)
per0_model2 = sum(best_half[,"model"] == "model2" & best_half[,"halflife"] < 0)
per0_model3 = sum(best_half[,"model"] == "model3" & best_half[,"halflife"] < 0)
pertmp_model1 = sum(best_half[,"model"] == "model1" & best_half[,"halflife"] > max(ts))
pertmp_model2 = sum(best_half[,"model"] == "model2" & best_half[,"halflife"] > max(ts))
pertmp_model3 = sum(best_half[,"model"] == "model3" & best_half[,"halflife"] > max(ts))
per1_model1 = sum(best_half[,"model"] == "model1" & best_half[,"halflife"] < -1)
per1_model2 = sum(best_half[,"model"] == "model2" & best_half[,"halflife"] < -1)
per1_model3 = sum(best_half[,"model"] == "model3" & best_half[,"halflife"] < -1)
per_stat <- data.frame(model = c("model1","model2","model3"),
                       Percent_model = c(per_model1,per_model2,per_model3),
                       below0 = c(per0_model1,per0_model2,per0_model3),
                       above_tmp = c(pertmp_model1,pertmp_model2,pertmp_model3),
                       below_minus1 = c(per1_model1, per1_model2, per1_model3))
write.csv(per_stat, file = "model_fitting_summary.txt", row.names = F, quote = F)

###

###Filter half-life below 0 and > max(ts)
#For half-lifes between -1 and 0 we round them up to 0
best_half$halflife <- replace(best_half$halflife,  best_half[,"halflife"] >= -1 & best_half[,"halflife"] <= 0, 0)
#Filter out other neg half life
best_half <- best_half[which(best_half$halflife > 0),]
#Filter out above 50
best_half <- best_half[which(best_half$halflife < 50),]

#writing half-life tsv file
write.table(best_half, file = "halflife_filtered.tsv", quote = F, row.names = F, sep = "\t")


# Bootstrap Conf intervals ------------------------------------------------
# setwd("/mnt/sharc/shared/sudlab1/General/projects/SLAMseq_CHO_Mikayla/cho_slam/slam/halflife/")
# dataframe_boostrap <- read.table(file = "ConvRate_processed.tsv")
dataframe_boostrap <- as.data.frame(ConvRate_rmbg_norm)
head(dataframe_boostrap)
std_0h <- dplyr::select(dataframe_boostrap, matches("-0h-")) %>% apply(1,sd)
mean_0h <- dplyr::select(dataframe_boostrap, matches("-0h-")) %>% apply(1,mean)

std_12h <- dplyr::select(dataframe_boostrap, matches("-12h-")) %>% apply(1,sd)
mean_12h <- dplyr::select(dataframe_boostrap, matches("-12h-")) %>% apply(1,mean)

std_3h <- dplyr::select(dataframe_boostrap, matches("-3h-")) %>% apply(1,sd)
mean_3h <- dplyr::select(dataframe_boostrap, matches("-3h-")) %>% apply(1,mean)

stat_data <- data.frame(mean_0h,std_0h,mean_12h,std_12h,mean_3h,std_3h)
head(stat_data)
#Getting stats on data separate timepoints

#Generating random data

random_half <- matrix(nrow = nrow(stat_data), ncol = 0)
random_half$id <- row.names(stat_data)
for (y in 1:100) {

  random_0h <- matrix(nrow = nrow(stat_data), ncol = 3, byrow = T)
  rownames(random_0h) <- rownames(stat_data)
  for (i in 1:nrow(stat_data)) {
    random <- rnorm(3, mean = stat_data[i,"mean_0h"], sd = stat_data[i,"std_0h"])
    random_0h[i,] <- random
  }

  random_3h <- matrix(nrow = nrow(stat_data), ncol = 3, byrow = T)
  rownames(random_3h) <- rownames(stat_data)
  for (i in 1:nrow(stat_data)) {
    random <- rnorm(3, mean = stat_data[i,"mean_3h"], sd = stat_data[i,"std_3h"])
    random_3h[i,] <- random
  }

  random_12h <- matrix(nrow = nrow(stat_data), ncol = 3, byrow = T)
  rownames(random_12h) <- rownames(stat_data)
  for (i in 1:nrow(stat_data)) {
    random <- rnorm(3, mean = stat_data[i,"mean_12h"], sd = stat_data[i,"std_12h"])
    random_12h[i,] <- random
  }

  random_data <- cbind(random_0h, random_12h, random_3h) %>% as.matrix()
  head(random_data)
  colnames(random_data) <- colnames(ConvRate_rmbg_norm)
  ts = str_extract(colnames(random_data), regex("(?<=-).+(?=h)")) %>% as.numeric()

  #Model 1
  
  fit_model1 <- function (expressions, times) {
    moptim1 <- function(a, expression){
      mRNA_guess = exp(-a * times)
      err = expression - mRNA_guess
      sq_err = err^2
      sumsq = sum(sq_err)
      return (sumsq)
    }
    
    outm <- optim(1, moptim1, expression=expressions)
    minm <- outm$value
    a_m <- outm$par[1]
    half1_m <- log(2)/a_m
    mod1half = half1_m
    
    mod1AIC = AIC1 = 2 + length(times)*log(minm)
    
    #n <- length(times)
    #RMSE <- sqrt(minm/n)
    return (c(thalf_m1=half1_m, AIC_m1=mod1AIC, a_m1 = a_m))
  }
  
  model1_fits <- apply(random_data, 1, fit_model1, times=ts)
  model1_fits <- t(model1_fits)
  
  
  fit_model2 <- function(expressions2, times2){
    moptim2 <- function(x,expression) {
      a = x[1]
      c = x[2]
      
      mRNA_guess = (1-c)*exp(-a*times2) + c
      diff = mRNA_guess - expression
      sumsqdiff= sum(diff^2)
      return(sumsqdiff)
    }
    outm2 <- optim(c(1,0), fn=moptim2, expression = expressions2, times2)
    a_m2 <- outm2$par[1]
    c_m2 <- outm2$par[2]
    
    model2_halfm <- function(x, a, c) {
      mRNA_half <- (1-c) * exp(-a*x) + c
      diff = mRNA_half - 0.5
      return (sum(diff^2))
    }
    out2_2m <- optim(1, fn = model2_halfm, a = a_m2, c = c_m2)
    mod2half <- out2_2m$par[1]
    
    mod2AIC = AIC2 = 4 + length(times2)*log(outm2$value)
    
    #n <- length(times)
    #RMSE <- sqrt(out2_2m$value/n)
    
    return (c(thalf_m2=mod2half, AIC_m2=mod2AIC, a_m2=a_m2, c_m2=c_m2))
  }
  
  model2_fits <- apply(random_data, 1, fit_model2, times2=ts)
  model2_fits <- t(model2_fits)
  #head(model2_fits)
  
  fit_model3 <- function (times3, expressions3){
    moptim3 <- function(x, expression){
      a = x[1]
      b = x[2]
      c = x[3]
      
      mRNA_guess = (1-c)*exp(-b*times3) + c*exp(-a*times3)
      diff = mRNA_guess - expression
      sumqdiff2 = sum(diff^2)
      return(sumqdiff2)
    }
    out3m <- optim(c(1,1,0.1), fn=moptim3, expression = expressions3, times3)
    a_m3 <- out3m$par[1]
    b_m3 <- out3m$par[2]
    c_m3 <- out3m$par[3]
    
    model3_halfm <- function(x, a,b,c){
      mRNA_halfm <- c * exp(-a*x)+(1-c)*exp(-b*x)
      diff = mRNA_halfm - 0.5
      return(sum(diff^2))
    }
    out3_3m <- optim(1, fn = model3_halfm, a = a_m3, b = b_m3, c = c_m3)
    mod3half3 <- out3_3m$par[1]
    
    mod3AIC = AIC3 = 6 + length(times3)*log(out3m$value)
    
    
    return(c(thalf_m3=mod3half3, AIC_m3 = mod3AIC, a_m3 = a_m3, b_m3 = b_m3, c_m3 = c_m3))
  }
  
  model3_fits <- apply(random_data, 1, fit_model3, times3=ts)
  model3_fits <- t(model3_fits)
  
  #head(model3_fits)

  #Models merge
  models_aic <- merge(model1_fits, model2_fits, by = "row.names")
  rownames(models_aic) <- models_aic[,1]
  models_aic[,1] <- NULL
  models_aic <- merge(models_aic, model3_fits, by = "row.names")
  head(models_aic)
  names(models_aic)[1] <- "id"

  rm(i)
  best_half <- matrix(nrow = nrow(models_aic), ncol = 3)
  for (i in 1:nrow(models_aic)) {
    best_half[i,] <- c(models_aic[i,"id"], models_aic[i,paste0("thalf_m",which.min(models_aic[i, c("AIC_m1","AIC_m2","AIC_m3")]) )], paste0("model",which.min(models_aic[i, c("AIC_m1","AIC_m2","AIC_m3")]) ))
  }
  best_half <- as.data.frame(best_half)
  head(best_half)
  colnames(best_half) <- c("id", paste0("bs_halflife_", y), paste0("bs_model_", y))
  random_half <- merge(random_half, best_half, by.x = "id")
  head(random_half)

}
#setwd("/mnt/sharc/fastdata/bo1cv/slam_herzog/new_utr_slam_all/count/bs")
write.table(random_half, file = "bootstrap_halflife.tsv", quote = F, sep = "\t", row.names = F)



# STREME ------------------------------------------------------------------

#
# ###Generate bed for streme
# #Order them and select for bed file
# best_half <- best_half[order(best_half$halflife),1:6]
# #Take the 10% most stable and less stable
# howmany <- (nrow(best_half) * 0.1) %>% round()
# most_stable <- head(best_half, n = howmany)
# less_stable <- tail(best_half, n = howmany)
# write.table(most_stable, file = "most_stable.bed", quote = F, row.names = F, sep = "\t", col.names = F)
# write.table(less_stable, file = "less_stable.bed", quote = F, row.names = F, sep = "\t", col.names = F)
